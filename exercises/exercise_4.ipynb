{
 "cells": [
  {
   "cell_type": "code",
   "id": "1a111b209c9c3761",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T11:06:01.850279Z",
     "start_time": "2025-08-03T11:06:01.834871Z"
    }
   },
   "source": [
    "# Standard Library Imports\n",
    "import os\n",
    "import time\n",
    "import subprocess\n",
    "\n",
    "# Third Party Imports\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from dask.distributed import Client\n",
    "from dask import array as da\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "\n",
    "# Local Imports\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Specify File System\n",
    "- Run `umask` to check our default file-creation permissions.\n",
    "- Create a fully writable `local_directory` for Zarr’s intermediate chunks (required by `map_overlap`).\n",
    "- Define `data_path` for the input Zarr dataset and `save_path` for the output Zarr.\n",
    "\n",
    "**What is `umask`?**\n",
    "\n",
    "The “user file-creation mode mask” that determines the default permissions for **new** files and directories.\n",
    "\n",
    "**How it works**\n",
    "\n",
    "  1. The system starts with a _full_ default permission (octal):\n",
    "     - **Files:** `666` (read/write for owner/group/others)\n",
    "     - **Dirs:**  `777` (read/write/execute for owner/group/others)\n",
    "  2. It then **subtracts** (bitwise) the umask value.\n",
    "     - Example: umask `022` → new files get `666 − 022 = 644` (`rw-r‐-r‐-`)\n",
    "                 new dirs get `777 − 022 = 755` (`rwx-r-xr-x`)\n",
    "\n",
    "- **Viewing your mask**\n",
    "  ```bash\n",
    "  $ umask\n",
    "  0022"
   ],
   "id": "79ad768c87dc1b9e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T11:09:51.836473Z",
     "start_time": "2025-08-03T11:09:51.769571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Figure out what your default `umask` setting is.\n",
    "result = subprocess.run(\"umask\", shell=True, capture_output=True, text=True)\n",
    "print(\"Subprocess umask:\", result.stdout.strip())\n",
    "\n",
    "# Create temporary directory and make sure that we have write privelages.\n",
    "local_directory=\"/project/bioinformatics/Danuser_lab/Dean/dean/dask_temp\"\n",
    "subprocess.run(f\"mkdir -p {local_directory} && chmod -R 777 {local_directory}\", shell=True)\n",
    "\n",
    "# Location of the data.\n",
    "base_path = \"/archive/bioinformatics/Danuser_lab/Dean/dean/2024-05-21-tiling\"\n",
    "data_path = os.path.join(base_path, \"cell5_fused_tp_0_ch_0.zarr\")\n",
    "save_path = os.path.join(base_path, 'example_4.zarr')\n"
   ],
   "id": "d403376cb17050e9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subprocess umask: 0022\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Specify your cluster's operating parameters.",
   "id": "2123813d39335372"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T10:58:04.919875Z",
     "start_time": "2025-08-03T10:58:04.903544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cluster_kwargs = {\n",
    "    'cores': 8, # Number of threads per worker (utilizing cores within each process)\n",
    "    'processes': 1, # Number of Python processes/worker.\n",
    "    'memory': '220GB', # Total memory to allocate for each worker job.\n",
    "    'local_directory': local_directory, #  Path for the Dask worker’s local storage (scratch space).\n",
    "    'interface': 'ib0', # Network interface identifier for Dask communications. Infiniband.\n",
    "    'walltime': \"01:00:00\", # The wall-time limit for each job, in HH:MM:SS.\n",
    "    'job_name': \"nanocourse\", # Name for the Slurm job, publicly visible via squeue command.\n",
    "    'queue': \"256GB\", # Slurm partition/queue to submit the jobs to\n",
    "    'death_timeout': \"600s\", #  Timeout (in seconds) for worker survival without a scheduler connection.\n",
    "    'job_extra_directives': [\n",
    "        # --nodes=1 and --ntasks=1 ensure each job runs on a single node with one task\n",
    "        \"--nodes=1\",\n",
    "        \"--ntasks=1\",\n",
    "        \"--mail-type=FAIL\",\n",
    "        \"--mail-user=kevin.dean@utsouthwestern.edu\",\n",
    "        \"-o job_%j.out\",\n",
    "        \"-e job_%j.err\",\n",
    "    ],\n",
    "    'scheduler_options': {\n",
    "        # A dictionary of settings passed to the Dask scheduler.\n",
    "        \"dashboard_address\": \":9000\",       # Dashboard web interface port\n",
    "        \"interface\": \"ib0\",\n",
    "\n",
    "        # Resource management\n",
    "        \"idle_timeout\": \"3600s\",            # How long workers stay alive when idle (1 hour)\n",
    "        \"allowed_failures\": 10,             # More failures allowed before worker marked as bad\n",
    "    },\n",
    "}\n"
   ],
   "id": "ccb6939dbcea1dc3",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Important `cluster_kwargs`\n",
    "\n",
    "-  cores: 8 – Total number of CPU cores allocated per Dask worker job. With processes=1, this means the single worker process will use 8 threads (8 cores) for parallel computations ￼. This value is also used by Slurm to request 8 CPUs for the job (effectively --cpus-per-task=8 when combined with one task).\n",
    "-  processes: 1 – Number of separate Python worker processes to start per job. Here 1 process will utilize all the threads/cores in the job. Using a single process is common if your tasks release the GIL or benefit from multi-threading; if tasks were pure Python (GIL-bound) or the node had many cores, you might increase this to spawn multiple smaller processes ￼ (each with cores/processes threads).\n"
   ],
   "id": "dc51d025090a03b0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Launch the Cluster",
   "id": "d61d86b000840b86"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-03T11:25:42.922119Z",
     "start_time": "2025-08-03T11:20:01.359750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "number_of_workers = 4\n",
    "cluster = SLURMCluster(**cluster_kwargs)\n",
    "cluster.scale(number_of_workers+1)\n",
    "client = Client(cluster)\n",
    "\n",
    "print(\"Waiting for workers to connect...\")\n",
    "start_time = time.time()\n",
    "timeout = 120\n",
    "while len(client.scheduler_info()['workers']) < number_of_workers:\n",
    "    if time.time() - start_time > timeout:\n",
    "        break\n",
    "    time.sleep(0.3)\n",
    "    if client.scheduler_info()['workers'] <= 1:\n",
    "        print(f\".\", end=\"\", flush=True)\n",
    "    else:\n",
    "        print(f\"{len(client.scheduler_info()['workers'])} connected\")\n",
    "\n",
    "print(f\"Client dashboard available at: {client.dashboard_link}\")\n",
    "\n",
    "# Load the Zarr file with Dask\n",
    "dask_data = da.from_zarr(data_path, component='0/0')\n",
    "data_shape = dask_data.shape\n",
    "\n",
    "# Eliminate singleton dimensions, and rechunk the data.\n",
    "dask_data = dask_data.squeeze()\n",
    "dask_data = dask_data.rechunk((32, 64, 64))\n",
    "\n",
    "# Process the data\n",
    "high_pass_filtered = dask_data.map_overlap(\n",
    "    ndimage.gaussian_filter, sigma=3, order=0, mode=\"nearest\", depth=40)\n",
    "\n",
    "low_pass_filtered = dask_data.map_overlap(\n",
    "    ndimage.gaussian_filter, sigma=10, order=0, mode=\"nearest\", depth=40)\n",
    "\n",
    "dog_filtered = da.map_blocks(\n",
    "    np.subtract, high_pass_filtered, low_pass_filtered)\n",
    "\n",
    "dog_filtered.to_zarr(save_path, overwrite=True)\n",
    "\n",
    "# Close the client and cluster\n",
    "client.close()\n",
    "cluster.close()\n",
    "print(\"Client and cluster closed.\")"
   ],
   "id": "408949e108bfa50",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/bioinformatics/Danuser_lab/Dean/dean/miniconda3/envs/dask-nanocourse/lib/python3.10/site-packages/distributed/node.py:187: UserWarning: Port 8788 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 46282 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for workers to connect...\n",
      "0 connected\n",
      "0 connected\n",
      "0 connected\n",
      "0 connected\n",
      "0 connected\n",
      "0 connected\n",
      "0 connected\n",
      "0 connected\n",
      "0 connected\n",
      "0 connected\n",
      "0 connected\n",
      "0 connected\n",
      "0 connected\n",
      "0 connected\n",
      "0 connected\n",
      "0 connected\n",
      "0 connected\n",
      "0 connected\n",
      "2 connected\n",
      "5 connected\n",
      "Client dashboard available at: http://10.100.160.4:46282/status\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Port Forwarding\n",
    "Dask will let you know which port the HTTP server is operating on. For example, it will state:\n",
    "`Hosting the HTTP server on port 44460 instead`. The address can be found from `client.dashboard_link`.\n",
    "\n",
    "To forward it to your local machine, run the following ssh command in your Terminal.\n",
    "`ssh -N -L 44460:localhost:44460 your-cluster-login@nucleus.biohpc.swmed.edu`\n"
   ],
   "id": "f0bd87da6a78b39c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
